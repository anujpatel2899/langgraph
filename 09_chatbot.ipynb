{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f474f801",
   "metadata": {},
   "source": [
    "## Simple Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68768cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain_core.messages import BaseMessage,HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a13208b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    # Schema\n",
    "    messages: Annotated[list[BaseMessage],add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1aea7937",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model =\"deepseek-r1-distill-llama-70b\")\n",
    "\n",
    "def chat_node(state:ChatState):\n",
    "    # take user query\n",
    "    messages = state['messages']\n",
    "\n",
    "    # send to llm\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    # response from llm to store in state\n",
    "    return {\"messages\":[response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7e738e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()\n",
    "graph = StateGraph(ChatState)\n",
    "\n",
    "# add node\n",
    "graph.add_node(\"chat_node\",chat_node)\n",
    "\n",
    "graph.add_edge(START,'chat_node')\n",
    "graph.add_edge('chat_node',END)\n",
    "\n",
    "\n",
    "chatbot = graph.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48c8bede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x109a23750>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6572e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, so I need to figure out what the capital of India is. Hmm, I'm not entirely sure, but I think it's one of the major cities there. Let me start by recalling what I know about India. I know it's a big country in South Asia with a rich history and diverse cultures. I've heard of cities like Mumbai, Delhi, Bangalore, and Kolkata. \\n\\nWait, Mumbai is a financial hub, right? So maybe that's not the capital. Bangalore is known for its tech industry, so probably not the capital either. Kolkata is more on the eastern side, I think. That leaves Delhi. I've heard Delhi being mentioned in the context of government and politics. \\n\\nBut I'm not 100% sure. Maybe I should think about other clues. I remember learning that some countries have their capitals not in the largest city. For example, in the US, the capital is Washington D.C., not New York or Los Angeles. So maybe India's capital isn't its largest city. \\n\\nI think Mumbai is the most populous city in India, but I'm not certain. If that's the case, then the capital might be a different city. Delhi comes to mind again. I also recall that New Delhi is the capital, but sometimes people refer to Delhi as the capital. So perhaps New Delhi is the official capital, and it's part of the larger Delhi region. \\n\\nI should also consider the government structure. The capital is where the central government is located, including the parliament and presidential residence. I believe the President of India resides in Rashtrapati Bhavan, which is in New Delhi. So that must be the capital. \\n\\nWait, I'm a bit confused because sometimes people just say Delhi, but technically, New Delhi is the capital. It's a planned city, part of the larger Delhi metropolitan area. So the distinction is important. \\n\\nTo confirm, I can think of other nearby cities. There's also Noida and Gurgaon near Delhi, but those are more satellite cities. The government buildings and embassies are in New Delhi, which strengthens the idea that New Delhi is the capital. \\n\\nI think I'm pretty confident now. New Delhi is the capital of India. It's where the central government is located, and it's part of the larger Delhi area. So when someone asks for the capital, the answer is New Delhi.\\n</think>\\n\\nThe capital of India is New Delhi. It serves as the administrative center, housing key government institutions such as the parliament and the President's residence, Rashtrapati Bhavan. While Delhi is the broader metropolitan area, New Delhi is specifically designated as the capital.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state = {\n",
    "    \"messages\": [HumanMessage(content=\"What is capital of India\")]\n",
    "}\n",
    "\n",
    "chatbot.invoke(initial_state)['messages'][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60b55799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:  hi my name is anuj\n",
      "AI:  <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Hi Anuj! How can I assist you today? ðŸ˜Š\n",
      "USER:  can u tell me my name?\n",
      "AI:  <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "I can't access personal information like your name. If you'd like, you can share it with me, and I'll do my best to assist you! ðŸ˜Š\n",
      "USER:  add 10 to 1000\n",
      "AI:  <think>\n",
      "\n",
      "</think>\n",
      "\n",
      "Sure! 10 added to 1000 is:\n",
      "\n",
      "10 + 1000 = **1010**\n",
      "USER:  now add another 10\n",
      "AI:  <think>\n",
      "I need to add 10 to the current number. Since the starting number isn't provided, I'll represent it with a variable, such as \\( n \\).\n",
      "\n",
      "First, I'll take the current number, which is \\( n \\).\n",
      "\n",
      "Next, I'll add 10 to \\( n \\) to find the sum.\n",
      "\n",
      "Therefore, the result of adding 10 is \\( n + 10 \\).\n",
      "</think>\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "To add another 10 to a number, follow these easy steps:\n",
      "\n",
      "1. **Start with the current number:**  \n",
      "   Let's assume the current number is \\( n \\).\n",
      "\n",
      "2. **Add 10 to the current number:**  \n",
      "   \\[\n",
      "   n + 10\n",
      "   \\]\n",
      "\n",
      "3. **Final Answer:**  \n",
      "   The result of adding 10 is:\n",
      "   \\[\n",
      "   \\boxed{n + 10}\n",
      "   \\]\n",
      "\n",
      "*Note:* If you provide the specific number you'd like to add 10 to, I can give you a numerical answer.\n",
      "USER:  bye\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    user_message = input(\"Type here: \")\n",
    "\n",
    "    print(\"USER: \",user_message)\n",
    "    if user_message.strip().lower() in ['exit','bye','quit']:\n",
    "        break\n",
    "\n",
    "    response =chatbot.invoke({\"messages\":[HumanMessage(content=user_message)]})\n",
    "    print(\"AI: \",response['messages'][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b0924e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER:  what is my name\n",
      "AI:  <think>\n",
      "\n",
      "Your name is **Anuj**! ðŸ˜Š How can I assist you today?\n",
      "USER:  you can be my assistant today help mex\n",
      "AI:  <think>\n",
      "Alright, let me try to figure out what the user is asking for here. So, looking back at the conversation history, the user's name is Anuj. They've asked a few questions so far: their name, simple math problems, and converting hours to seconds. \n",
      "\n",
      "Now, in their latest message, they wrote, \"you can be my assistant today help mex.\" I think there might be a typo there. It probably should be \"help me\" instead of \"help mex.\" So, they're asking if I can be their assistant today and help them with something.\n",
      "\n",
      "Since I've already been assisting them with their previous questions, it seems like they're confirming if I can continue helping them. They might have more questions or need further assistance. \n",
      "\n",
      "I should respond positively, reassure them that I'm here to help, and maybe ask how I can assist them today. Keeping the tone friendly and approachable would be best. \n",
      "\n",
      "So, my response should be something like, \"Of course, Anuj! I'm here to help you with whatever you need today. Just let me know how I can assist you!\" That way, I'm acknowledging their request, confirming my role as their assistant, and inviting them to specify what they need help with.\n",
      "</think>\n",
      "\n",
      "Of course, Anuj! I'm here to help you with whatever you need today. Just let me know how I can assist you! ðŸ˜Š\n",
      "USER:  bye\n"
     ]
    }
   ],
   "source": [
    "# Adding Persistent Memory\n",
    "thread_id = '1'\n",
    "\n",
    "while True:\n",
    "\n",
    "    user_message = input(\"Type here: \")\n",
    "\n",
    "    print(\"USER: \",user_message)\n",
    "    if user_message.strip().lower() in ['exit','bye','quit']:\n",
    "        break\n",
    "    \n",
    "    config = {'configurable':{\"thread_id\":thread_id}}\n",
    "    response =chatbot.invoke({\"messages\":[HumanMessage(content=user_message)]},config=config)\n",
    "    print(\"AI: \",response['messages'][-1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9012e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi my name is Anuj', additional_kwargs={}, response_metadata={}, id='eabdb21c-9df5-4b7a-b8ff-50737e3276a4'), AIMessage(content='<think>\\n\\n</think>\\n\\nHi Anuj! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 9, 'total_tokens': 27, 'completion_time': 0.09788769, 'prompt_time': 0.000203656, 'queue_time': 0.057746464, 'total_time': 0.098091346}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--82585cb0-0a5b-4a3d-a209-0804c3bbee44-0', usage_metadata={'input_tokens': 9, 'output_tokens': 18, 'total_tokens': 27}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}, id='9633703b-8d8c-46ec-91e2-fff2af030413'), AIMessage(content='<think>\\nAlright, the user just asked, \"what is my name.\" Looking back at the conversation history, they introduced themselves as Anuj in the first message.\\n\\nI should confirm their name based on the information they provided. Since they mentioned it earlier, I can confidently tell them their name is Anuj.\\n\\nI should respond in a friendly and helpful manner, maybe add an emoji to keep the tone positive. Let me make sure my response is clear and direct.\\n</think>\\n\\nYour name is Anuj! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 30, 'total_tokens': 134, 'completion_time': 0.539905465, 'prompt_time': 0.001327048, 'queue_time': 0.052347722, 'total_time': 0.541232513}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--80867aa9-cd94-4bd8-b021-8d787d7c8943-0', usage_metadata={'input_tokens': 30, 'output_tokens': 104, 'total_tokens': 134}), HumanMessage(content='what is 100 + 100', additional_kwargs={}, response_metadata={}, id='4a4d7792-8097-44e3-845a-7cd87034b4d5'), AIMessage(content='<think>\\n\\n100 + 100 equals 200.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 49, 'total_tokens': 60, 'completion_time': 0.048059415, 'prompt_time': 0.002467649, 'queue_time': 0.052468350999999996, 'total_time': 0.050527064}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3bfb8f5c-fb20-4e76-8f6a-a543a347229a-0', usage_metadata={'input_tokens': 49, 'output_tokens': 11, 'total_tokens': 60}), HumanMessage(content='add another 1000', additional_kwargs={}, response_metadata={}, id='24f07644-0d5b-43da-9b14-447be1217abf'), AIMessage(content='<think>\\nOkay, so the user is asking me to add another 1000. Let me see the conversation history to understand the context better. Earlier, they asked, \"what is 100 + 100,\" and I replied that it\\'s 200. Now, they\\'re saying, \"add another 1000.\" Hmm, they might be continuing the math problem.\\n\\nI think they want to add 1000 to the previous sum of 200. So, 200 plus 1000 would be 1200. That seems straightforward. I should make sure to present it clearly and maybe offer further help in case they have more questions. It\\'s important to keep the tone friendly and open-ended to encourage them to continue the conversation if needed.\\n</think>\\n\\nSure! If you\\'re continuing from the previous calculation of 100 + 100 = 200, adding another 1000 would make it:\\n\\n200 + 1000 = **1200**\\n\\nLet me know if you\\'d like help with anything else! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 207, 'prompt_tokens': 57, 'total_tokens': 264, 'completion_time': 0.916273616, 'prompt_time': 0.002904902, 'queue_time': 0.051767047999999996, 'total_time': 0.919178518}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--28465697-759a-45e1-b03e-551bfc26d970-0', usage_metadata={'input_tokens': 57, 'output_tokens': 207, 'total_tokens': 264}), HumanMessage(content='can  u telll me the seconds in 2 hour', additional_kwargs={}, response_metadata={}, id='dd5f0fcc-562c-4703-941a-d0974235693a'), AIMessage(content=\"<think>\\nAlright, the user is asking for the number of seconds in 2 hours. Let me break this down step by step to make sure I get it right.\\n\\nFirst, I know that time conversions often involve multiplying by 60. So, starting with hours, I need to convert hours to minutes. There are 60 minutes in an hour, so for 2 hours, that's 2 multiplied by 60.\\n\\n2 hours * 60 minutes/hour = 120 minutes.\\n\\nNow, I need to convert minutes to seconds. There are 60 seconds in a minute, so I take the 120 minutes and multiply by 60 again.\\n\\n120 minutes * 60 seconds/minute = 7200 seconds.\\n\\nSo, putting it all together, 2 hours is equal to 7,200 seconds. I think that's straightforward, but maybe the user is working on a project that requires precise time measurements or perhaps they're dealing with something like video editing or coding where exact seconds matter. Either way, providing the step-by-step calculation helps ensure clarity and reduces any chance of confusion.\\n</think>\\n\\nSure! Let's break it down step by step:\\n\\n1. **Hours to Minutes**:  \\n   2 hours Ã— 60 minutes/hour = 120 minutes\\n\\n2. **Minutes to Seconds**:  \\n   120 minutes Ã— 60 seconds/minute = 7,200 seconds\\n\\nSo, there are **7,200 seconds** in 2 hours. ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 300, 'prompt_tokens': 126, 'total_tokens': 426, 'completion_time': 1.120370752, 'prompt_time': 0.008119506, 'queue_time': 0.052395384, 'total_time': 1.128490258}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e56a173f-eeca-4248-b080-01b659695330-0', usage_metadata={'input_tokens': 126, 'output_tokens': 300, 'total_tokens': 426}), HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='d864c0a9-b750-4e90-b58a-24778772f503'), AIMessage(content='<think>\\n\\nHello! How can I assist you today? ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 207, 'total_tokens': 221, 'completion_time': 0.061076831, 'prompt_time': 0.012777259, 'queue_time': 0.052383781000000004, 'total_time': 0.07385409}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--3eb426cc-7848-43ad-bbe4-2536c86b1654-0', usage_metadata={'input_tokens': 207, 'output_tokens': 14, 'total_tokens': 221}), HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={}, id='2d432897-0386-4238-9013-f4874f7b04c0'), AIMessage(content='<think>\\n\\nYour name is **Anuj**! ðŸ˜Š How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 214, 'total_tokens': 234, 'completion_time': 0.076271204, 'prompt_time': 0.013147714, 'queue_time': 0.061342006, 'total_time': 0.089418918}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--631a6d8f-514f-44a6-88d2-fcc625a69bbd-0', usage_metadata={'input_tokens': 214, 'output_tokens': 20, 'total_tokens': 234}), HumanMessage(content='you can be my assistant today help mex', additional_kwargs={}, response_metadata={}, id='432733c3-215d-4002-bb9a-c4fe4af65bce'), AIMessage(content='<think>\\nAlright, let me try to figure out what the user is asking for here. So, looking back at the conversation history, the user\\'s name is Anuj. They\\'ve asked a few questions so far: their name, simple math problems, and converting hours to seconds. \\n\\nNow, in their latest message, they wrote, \"you can be my assistant today help mex.\" I think there might be a typo there. It probably should be \"help me\" instead of \"help mex.\" So, they\\'re asking if I can be their assistant today and help them with something.\\n\\nSince I\\'ve already been assisting them with their previous questions, it seems like they\\'re confirming if I can continue helping them. They might have more questions or need further assistance. \\n\\nI should respond positively, reassure them that I\\'m here to help, and maybe ask how I can assist them today. Keeping the tone friendly and approachable would be best. \\n\\nSo, my response should be something like, \"Of course, Anuj! I\\'m here to help you with whatever you need today. Just let me know how I can assist you!\" That way, I\\'m acknowledging their request, confirming my role as their assistant, and inviting them to specify what they need help with.\\n</think>\\n\\nOf course, Anuj! I\\'m here to help you with whatever you need today. Just let me know how I can assist you! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 289, 'prompt_tokens': 225, 'total_tokens': 514, 'completion_time': 1.137793813, 'prompt_time': 0.013805963, 'queue_time': 0.05780680700000001, 'total_time': 1.151599776}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--97cc8099-1d32-4a9e-95f3-2cb6a62d5d82-0', usage_metadata={'input_tokens': 225, 'output_tokens': 289, 'total_tokens': 514})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06dbb5-86b7-6934-8016-89b6e94c854e'}}, metadata={'source': 'loop', 'step': 22, 'parents': {}}, created_at='2025-07-31T03:06:25.823542+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f06dbb5-7a60-6e10-8015-a9bb2afc3116'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0b8af4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
